{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGRDOIrTaBEL"
      },
      "source": [
        "# **Códigos utilizados nos dados**\n",
        "\n",
        "Iniciar importando os pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHN0bEQtaBEN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unidecode import unidecode\n",
        "import os\n",
        "import requests\n",
        "from dbfread import DBF\n",
        "import psycopg2\n",
        "from sqlalchemy import create_engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQs-fdSgaBEO"
      },
      "source": [
        "## Leitor auxilair para arquivos .dbc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU7qhdgtaBEO"
      },
      "source": [
        "Caso o arquivo esteja no formato .dbc, ao invés de carregar com pd.read_csv(), utilize:\n",
        "\n",
        "`dbf_to_dataframe(Caminho da pasta/nome_do_arquivo.dbf)`\n",
        "\n",
        "Essa funçao carrega o arquivo .dbc e converte em um pandas dataframe,  <br>\n",
        "assim será mais simples de manipular e converter para outros formatos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzXLbSiZaBEO"
      },
      "source": [
        "## *Código*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRVwwTvTaBEP"
      },
      "outputs": [],
      "source": [
        "# Criar uma variável para substituir `pasta` com o caminho do arquivo\n",
        "def dbf_to_dataframe(pasta):\n",
        "    # Lista vazia\n",
        "    dados = []\n",
        "    # Ler o DBF e fazer append na lista vazia\n",
        "    for dado in DBF(pasta, encoding='latin1'):\n",
        "        dados.append(dado)\n",
        "\n",
        "    # Converter em dadosframe\n",
        "    return pd.DataFrame(dados)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5_UCnllaBEP"
      },
      "source": [
        "## Loop para concatenar os dataframes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfzpOGEUaBEP"
      },
      "source": [
        "\n",
        "1 - O código criaa um DataFrame vazio chamado `concatenated_df` que será usado para armazenar os dados de todos os arquivos CSV concatenados.\n",
        "<br>\n",
        "<br>\n",
        "2 - É definida a variável `folder_path`, que representa o caminho do diretório onde os arquivos CSV estão localizados.\n",
        "<br>\n",
        "<br>\n",
        "3 - É definida uma função chamada `anything(df)`, que recebe um DataFrame df como entrada e retorna o mesmo DataFrame sem fazer qualquer alteração nele.\n",
        "<br>\n",
        "<br>\n",
        "4 - O código entra em um `loop for` para percorrer cada arquivo no diretório `folder_path`\n",
        "<br>\n",
        "<br>\n",
        "5 - É verificado se o nome do arquivo começa com \"SIM\" e termina com a extensão \".csv\". Se sim, o arquivo é processado\n",
        "<br>\n",
        "<br>\n",
        "6 - O caminho completo do arquivo é construído usando `os.path.join()` com base no caminho do diretório `folder_path` e o nome do arquivo atual (`filename`).\n",
        "<br>\n",
        "<br>\n",
        "7 - `pd.read_csv()` é usado para ler o arquivo CSV em um DataFrame chamado df. Os parâmetros `sep=';'` e `encoding='latin1'` especificam que o separador no arquivo CSV é ponto e vírgula e a codificação é 'latin1'.\n",
        "<br>\n",
        "<br>\n",
        "8 - O DataFrame df é passado para a função `nada()` definida anteriormente. Essa função não faz nenhuma alteração no DataFrame, então o DataFrame tratado (`treated_df`) será idêntico ao DataFrame original.\n",
        "<br>\n",
        "<br>\n",
        "9 - O DataFrame tratado (`treated_df`) é então concatenado com o DataFrame `concatenated_df` usando `pd.concat()`. A concatenação é feita ao longo das linhas, o que significa que os dados dos arquivos CSV são empilhados verticalmente no DataFrame `concatenated_df`.\n",
        "<br>\n",
        "<br>\n",
        "10 - Após o loop ser concluído e todos os arquivos CSV serem processados e concatenados, o índice do DataFrame `concatenated_df` é redefinido usando `reset_index(drop=True, inplace=True)`. Isso garante que o índice seja redefinido sequencialmente de 0 até o número total de linhas no DataFrame concatenado, e o parâmetro `drop=True` indica que o índice anterior será descartado.\n",
        "<br>\n",
        "<br>\n",
        "11 - O código `display()` exibe o novo DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKl0Pz8RaBEP"
      },
      "source": [
        "## *Códigos*\n",
        "1 - Concatenar .csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoQ-SYgaaBEQ"
      },
      "outputs": [],
      "source": [
        "#1 - DataFrame vazio para armazenar os dados concatenados\n",
        "concatenated_df = pd.DataFrame()\n",
        "\n",
        "#2 - Pasta onde os dados estão armazenados\n",
        "folder_path = 'dado_tratado'\n",
        "\n",
        "#3 - Funçao\n",
        "def anything(df):\n",
        "    return df\n",
        "\n",
        "#4 - Loop nos arquivos no diretório\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.startswith(f'SIM') and filename.endswith('.csv'):  #5 - Construção do nome do arquivo\n",
        "        file_path = os.path.join(folder_path, filename)            #6 - Construção do caminho completo\n",
        "        df = pd.read_csv(file_path,sep = ';', encoding='latin1')   #7 - Leitura do arquivo\n",
        "\n",
        "        # Selecionar colunas\n",
        "        #df = df[['']]\n",
        "        treated_df = anything(df)                                  #8 - Aplica a função que retorna o mesmo df\n",
        "        concatenated_df = pd.concat([concatenated_df, treated_df]) #9 - Concatena os df\n",
        "\n",
        "#10 - Reset index e concatenando em um DataFrame\n",
        "concatenated_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "#11 - Display the final concatenated DataFrame\n",
        "display(concatenated_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TcbqC2NaBER"
      },
      "source": [
        "2 - Concatenar DBF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg5K7nHyaBER"
      },
      "outputs": [],
      "source": [
        "#1 - DataFrame vazio para armazenar os dados concatenados\n",
        "concatenated_df = pd.DataFrame()\n",
        "\n",
        "#2 - Pasta onde os dados estão armazenados\n",
        "folder_path = 'C:\\\\vitalstrategies\\\\data_sicence\\\\VIOLBR18.dbf'\n",
        "\n",
        "#3 - Funçao\n",
        "def anything(df):\n",
        "    return df\n",
        "\n",
        "#4 - Loop nos arquivos no diretório\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.startswith(f'VIOLBR') and filename.endswith('.dbf'):  #5 - Construção do nome do arquivo\n",
        "        file_path = os.path.join(folder_path, filename)               #6 - Construção do caminho completo\n",
        "        df = dbf_to_dataframe(file_path)                              #7 - Leitura do arquivo\n",
        "\n",
        "        # Selecionar colunas\n",
        "        df = df[[\n",
        "            'ID_AGRAVO',\n",
        "            'DT_NOTIFIC',\n",
        "            'NU_ANO'\n",
        "            ]]\n",
        "\n",
        "        treated_df = anything(df)                                     #8 - Aplica a função que retorna o mesmo df\n",
        "        concatenated_df = pd.concat([concatenated_df, treated_df])    #9 - Concatena os df\n",
        "\n",
        "#10 - Reset index e concatenando em um DataFrame\n",
        "concatenated_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "#11 - Display the final concatenated DataFrame\n",
        "display(concatenated_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DasRHx6JaBES"
      },
      "source": [
        "## Salvar o DataFrame direto no banco Postgres\n",
        "Exemplo de como inputar um dataframe no postgres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNx2EvgbaBES"
      },
      "outputs": [],
      "source": [
        "# Carregar os dados\n",
        "df = pd.read_csv('C:/vitalstrategies/data_sicence/ISM/Dados/ipea/ipea_indicadores/ivs_ipea.csv', sep = ';')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DemV-BllaBES"
      },
      "source": [
        "exemplo de alterações possíveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNFGpQ1_aBES"
      },
      "outputs": [],
      "source": [
        "# Seleção das variáveis\n",
        "df = df[['Município', 'Ano', 'IVS', 'IVS Infraestrutura Urbana', 'IVS Capital Humano', 'IVS Renda e Trabalho', 'UF']]\n",
        "\n",
        "# Renomeando as variáveis\n",
        "df = df.rename(columns={\n",
        "    'Município': 'ibge_muni',\n",
        "    'Ano' : 'id_ano',\n",
        "    'IVS': 'ivs',\n",
        "    'IVS Infraestrutura Urbana': 'ivs_infra_urb',\n",
        "    'IVS Capital Humano': 'ivs_cap_hum',\n",
        "    'IVS Renda e Trabalho': 'ivs_rend_trab',\n",
        "    'UF': 'uf'\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLlo_N-6aBES"
      },
      "outputs": [],
      "source": [
        "colunas = ['UF', 'Município', 'Ano', 'IVS']\n",
        "df = df[colunas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBMH6y41aBES",
        "outputId": "d3aad179-e8aa-4a78-ab23-dffec4483eef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dados carregados com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Configurações do banco de dados\n",
        "db_config = {\n",
        "    'host': 'ls-5ae56aeb2ca5d6cbcd113e0c1aaa14c2a5395de9.c1ozwzg2gdjm.us-east-1.rds.amazonaws.com',\n",
        "    'database': 'postgres',\n",
        "    'user': 'postgresql_vs_public',\n",
        "    'password': '>D,&g-5ZURExX=e-t]8?UXL2j!9B;xtc',\n",
        "}\n",
        "\n",
        "###################################################################\n",
        "## Nome da tabela que será inputada/atualizada no banco de dados ##\n",
        "###################################################################\n",
        "nome_tabela = 'tb_pop_ms'\n",
        "\n",
        "\n",
        "\n",
        "# Código que tenta conectar ao banco e carregar o dataframe\n",
        "try:\n",
        "    # Conecta ao banco de dados usando o SQLAlchemy\n",
        "    engine = create_engine(f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}/{db_config['database']}\")\n",
        "\n",
        "    # Carrega o DataFrame para o banco de dados\n",
        "    concatenated_df.to_sql(dataframe_2021, engine, if_exists='append', index=False) # alterar \"replace\" no if_exists para \"append\" e testar com as novas variaveis\n",
        "\n",
        "    # Caso dê certo\n",
        "    print(\"Dados carregados com sucesso!\")\n",
        "\n",
        "    # Caso não dê certo\n",
        "except (psycopg2.Error, Exception) as e:\n",
        "    print(\"Erro ao conectar ao PostgreSQL ou carregar os dados:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1GtcDwpaBES",
        "outputId": "c20d425b-74d9-4976-d3aa-6dc8c0876573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arquivo VIOLBR10.dbf carregado e concatenado.\n",
            "Arquivo VIOLBR11.dbf carregado e concatenado.\n",
            "Arquivo VIOLBR12.dbf carregado e concatenado.\n",
            "Arquivo VIOLBR13.dbf carregado e concatenado.\n",
            "Arquivo VIOLBR14.dbf carregado e concatenado.\n",
            "Arquivo VIOLBR15.dbf carregado e concatenado.\n",
            "Arquivo VIOLBR16.dbf carregado e concatenado.\n",
            "Arquivo VIOLBR17.dbf carregado e concatenado.\n",
            "Arquivo VIOLBR18.dbf carregado e concatenado.\n",
            "Arquivo VIOLBR19.dbf carregado e concatenado.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_MUNICIP</th>\n",
              "      <th>TP_NOT</th>\n",
              "      <th>ID_AGRAVO</th>\n",
              "      <th>DT_NOTIFIC</th>\n",
              "      <th>DT_OCOR</th>\n",
              "      <th>ANO_NASC</th>\n",
              "      <th>NU_IDADE_N</th>\n",
              "      <th>CS_SEXO</th>\n",
              "      <th>CS_RACA</th>\n",
              "      <th>ID_MN_RESI</th>\n",
              "      <th>LES_AUTOP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500370</td>\n",
              "      <td>2</td>\n",
              "      <td>Y09</td>\n",
              "      <td>2010-01-10</td>\n",
              "      <td>2010-01-10</td>\n",
              "      <td>1997</td>\n",
              "      <td>4012</td>\n",
              "      <td>F</td>\n",
              "      <td>9</td>\n",
              "      <td>500370</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>221130</td>\n",
              "      <td>2</td>\n",
              "      <td>Y09</td>\n",
              "      <td>2010-02-02</td>\n",
              "      <td>2010-02-02</td>\n",
              "      <td>1994</td>\n",
              "      <td>4015</td>\n",
              "      <td>M</td>\n",
              "      <td>2</td>\n",
              "      <td>221130</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>230526</td>\n",
              "      <td>2</td>\n",
              "      <td>Y09</td>\n",
              "      <td>2010-01-01</td>\n",
              "      <td>2010-01-01</td>\n",
              "      <td>1994</td>\n",
              "      <td>4015</td>\n",
              "      <td>F</td>\n",
              "      <td>4</td>\n",
              "      <td>230526</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>292660</td>\n",
              "      <td>2</td>\n",
              "      <td>Y09</td>\n",
              "      <td>2010-01-08</td>\n",
              "      <td>2010-01-08</td>\n",
              "      <td>1973</td>\n",
              "      <td>4036</td>\n",
              "      <td>F</td>\n",
              "      <td>2</td>\n",
              "      <td>292660</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>251398</td>\n",
              "      <td>2</td>\n",
              "      <td>Y09</td>\n",
              "      <td>2010-01-15</td>\n",
              "      <td>2010-01-15</td>\n",
              "      <td>1962</td>\n",
              "      <td>4047</td>\n",
              "      <td>F</td>\n",
              "      <td>4</td>\n",
              "      <td>251398</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259571</th>\n",
              "      <td>310670</td>\n",
              "      <td>2</td>\n",
              "      <td>Y09</td>\n",
              "      <td>2019-03-21</td>\n",
              "      <td>2019-03-07</td>\n",
              "      <td>1994</td>\n",
              "      <td>4024</td>\n",
              "      <td>F</td>\n",
              "      <td>9</td>\n",
              "      <td>310670</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259572</th>\n",
              "      <td>310670</td>\n",
              "      <td>2</td>\n",
              "      <td>Y09</td>\n",
              "      <td>2019-02-01</td>\n",
              "      <td>2018-07-11</td>\n",
              "      <td>1957</td>\n",
              "      <td>4061</td>\n",
              "      <td>F</td>\n",
              "      <td>4</td>\n",
              "      <td>310670</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259573</th>\n",
              "      <td>310670</td>\n",
              "      <td>2</td>\n",
              "      <td>Y09</td>\n",
              "      <td>2019-03-06</td>\n",
              "      <td>2019-02-27</td>\n",
              "      <td>1986</td>\n",
              "      <td>4032</td>\n",
              "      <td>F</td>\n",
              "      <td>9</td>\n",
              "      <td>310670</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259574</th>\n",
              "      <td>310670</td>\n",
              "      <td>2</td>\n",
              "      <td>Y09</td>\n",
              "      <td>2019-03-06</td>\n",
              "      <td>2019-03-01</td>\n",
              "      <td>1990</td>\n",
              "      <td>4028</td>\n",
              "      <td>F</td>\n",
              "      <td>9</td>\n",
              "      <td>310670</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259575</th>\n",
              "      <td>310670</td>\n",
              "      <td>2</td>\n",
              "      <td>Y09</td>\n",
              "      <td>2019-02-14</td>\n",
              "      <td>2019-02-13</td>\n",
              "      <td>2015</td>\n",
              "      <td>4003</td>\n",
              "      <td>F</td>\n",
              "      <td>1</td>\n",
              "      <td>310900</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2259576 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID_MUNICIP  TP_NOT ID_AGRAVO  DT_NOTIFIC     DT_OCOR  ANO_NASC  \\\n",
              "0            500370       2       Y09  2010-01-10  2010-01-10      1997   \n",
              "1            221130       2       Y09  2010-02-02  2010-02-02      1994   \n",
              "2            230526       2       Y09  2010-01-01  2010-01-01      1994   \n",
              "3            292660       2       Y09  2010-01-08  2010-01-08      1973   \n",
              "4            251398       2       Y09  2010-01-15  2010-01-15      1962   \n",
              "...             ...     ...       ...         ...         ...       ...   \n",
              "2259571      310670       2       Y09  2019-03-21  2019-03-07      1994   \n",
              "2259572      310670       2       Y09  2019-02-01  2018-07-11      1957   \n",
              "2259573      310670       2       Y09  2019-03-06  2019-02-27      1986   \n",
              "2259574      310670       2       Y09  2019-03-06  2019-03-01      1990   \n",
              "2259575      310670       2       Y09  2019-02-14  2019-02-13      2015   \n",
              "\n",
              "         NU_IDADE_N CS_SEXO  CS_RACA  ID_MN_RESI  LES_AUTOP  \n",
              "0              4012       F        9      500370          1  \n",
              "1              4015       M        2      221130          2  \n",
              "2              4015       F        4      230526          2  \n",
              "3              4036       F        2      292660          2  \n",
              "4              4047       F        4      251398          2  \n",
              "...             ...     ...      ...         ...        ...  \n",
              "2259571        4024       F        9      310670          2  \n",
              "2259572        4061       F        4      310670          2  \n",
              "2259573        4032       F        9      310670          1  \n",
              "2259574        4028       F        9      310670          1  \n",
              "2259575        4003       F        1      310900          2  \n",
              "\n",
              "[2259576 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unidecode import unidecode\n",
        "import os\n",
        "import requests\n",
        "from dbfread import DBF\n",
        "import psycopg2\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "\n",
        "###################################################################\n",
        "## Nome da tabela que será inputada/atualizada no banco de dados ##\n",
        "###################################################################\n",
        "\n",
        "# Nome que da tabela para o SQL\n",
        "nome_tabela = 'tb_sinan_viol'\n",
        "\n",
        "# Pasta onde os dados estão armazenados\n",
        "folder_path = 'C:/Users/João Miguel/OneDrive/Documentos/Python Scripts/dado_convertido_dbf'\n",
        "# Iniciais do arquivo\n",
        "arquivo = 'VIOLBR1'\n",
        "\n",
        "# Seleção das variáveis\n",
        "variaveis_selecionadas = ['ID_MUNICIP',\n",
        "                        'TP_NOT',\n",
        "                         'ID_AGRAVO',\n",
        "                         'DT_NOTIFIC',\n",
        "                         'DT_OCOR',\n",
        "                         #'DT_NASC',\n",
        "                         'ANO_NASC',\n",
        "                         'NU_IDADE_N',\n",
        "                         'CS_SEXO',\n",
        "                         'CS_RACA',\n",
        "                         'ID_MN_RESI',\n",
        "                         'LES_AUTOP']\n",
        "\n",
        "\n",
        "def tratamento(df):\n",
        "    df['ID_MUNICIP'] = df['ID_MUNICIP'].astype('int')\n",
        "    df['TP_NOT'] = df['TP_NOT'].astype('int')\n",
        "    df['ANO_NASC'] = df['ANO_NASC'].replace('','1800').astype('int')\n",
        "    df['NU_IDADE_N'] = df['NU_IDADE_N'].replace(np.nan,999).astype('int')\n",
        "    df['CS_RACA'] = df['CS_RACA'].replace('','999').astype(int)\n",
        "    df['ID_MN_RESI'] = df['ID_MN_RESI'].replace('','999').astype('int')\n",
        "    df['LES_AUTOP'] = df['LES_AUTOP'].replace('','9').astype('int')\n",
        "    return df\n",
        "\n",
        "\n",
        "###################################################################\n",
        "## Código para carregar, selecionar variáveis e inputar no Banco ##\n",
        "###################################################################\n",
        "\n",
        "\n",
        "# Criar uma variável para substituir `pasta` com o caminho do arquivo\n",
        "def dbf_to_dataframe(pasta):\n",
        "    # Lista vazia\n",
        "    dados = []\n",
        "    # Ler o DBF e fazer append na lista vazia\n",
        "    for dado in DBF(pasta, encoding='latin1'):\n",
        "        dados.append(dado)\n",
        "\n",
        "    # Converter em dadosframe\n",
        "    return pd.DataFrame(dados)\n",
        "\n",
        "\n",
        "# Função para ler o arquivo com base na extensão\n",
        "def pandas_read(file_path):\n",
        "    _, file_extension = os.path.splitext(file_path)\n",
        "\n",
        "    if file_extension == '.csv':\n",
        "        return pd.read_csv(file_path, sep=';', encoding='latin1')\n",
        "    elif file_extension == '.dbf':\n",
        "        return dbf_to_dataframe(file_path)  # Substitua a função dbf_to_dataframe pela função correta para ler arquivos .dbf\n",
        "    else:\n",
        "        raise ValueError(f\"Tipo de arquivo não suportado: {file_extension}\")\n",
        "\n",
        "# DataFrame vazio para armazenar os dados concatenados\n",
        "concatenated_df = pd.DataFrame()\n",
        "\n",
        "# Loop nos arquivos no diretório\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.startswith(arquivo) and (filename.endswith('.csv') or filename.endswith('.dbf')):\n",
        "        file_path = os.path.join(folder_path, filename)             # Construção do caminho completo\n",
        "        df = pandas_read(file_path)                                 # Leitura do arquivo\n",
        "\n",
        "        # Lista de colunas selecionadas (adicione as colunas desejadas aqui)\n",
        "        df = df[variaveis_selecionadas]\n",
        "\n",
        "        df = tratamento(df)\n",
        "\n",
        "        treated_df = df.copy()                                      # Aplica a função que retorna o mesmo df\n",
        "        concatenated_df = pd.concat([concatenated_df, treated_df])\n",
        "\n",
        "        print(f\"Arquivo {filename} carregado e concatenado.\")\n",
        "# Reset index e concatenando em um DataFrame\n",
        "concatenated_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display do DataFrame concatenado\n",
        "display(concatenated_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC556thxaBET",
        "outputId": "9521d0a4-d664-4303-8463-0007d4591c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dados carregados com sucesso!\n"
          ]
        }
      ],
      "source": [
        "#####################################\n",
        "## Configurações do banco de dados ##\n",
        "#####################################\n",
        "\n",
        "db_config = {\n",
        "    'host': 'ls-5ae56aeb2ca5d6cbcd113e0c1aaa14c2a5395de9.c1ozwzg2gdjm.us-east-1.rds.amazonaws.com',\n",
        "    'database': 'postgres',\n",
        "    'user': 'postgresql_vs_public',\n",
        "    'password': '>D,&g-5ZURExX=e-t]8?UXL2j!9B;xtc',\n",
        "}\n",
        "\n",
        "# Código que tenta conectar ao banco e carregar o dataframe\n",
        "try:\n",
        "    # Conecta ao banco de dados usando o SQLAlchemy\n",
        "    engine = create_engine(f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}/{db_config['database']}\")\n",
        "\n",
        "    # Carrega o DataFrame para o banco de dados\n",
        "    concatenated_df.to_sql(nome_tabela, engine, if_exists='replace', index=False) # alterar \"replace\" no if_exists para \"append\" e testar com as novas variaveis\n",
        "\n",
        "    # Caso dê certo\n",
        "    print(\"Dados carregados com sucesso!\")\n",
        "\n",
        "    # Caso não dê certo\n",
        "except (psycopg2.Error, Exception) as e:\n",
        "    print(\"Erro ao conectar ao PostgreSQL ou carregar os dados:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEINkqZTaBET"
      },
      "outputs": [],
      "source": [
        "folder_path = ''\n",
        "# Iniciais do arquivo\n",
        "arquivo = ''\n",
        "\n",
        "a =dbf_to_dataframe('C:\\\\vitalstrategies\\\\data_sicence\\\\VIOLBR18.dbf')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}